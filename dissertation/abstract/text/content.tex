\section{Краткое содержание работы}

В \textbf{первой главе} сформулирована задача идентификации стохастических систем как
задача оценивания параметров и состояния системы по результатам наблюдений над
входными и выходными переменными, полученными в условиях её функционирования:
\begin{equation*}
  \label{eq:model_general}
  \begin{aligned}
    \overline{\eta} &= \psi (\overline{\theta}, \overline{\xi}), \\
    \overline{x} &= \overline{\xi} + \overline{\varepsilon_x}, \\
    \overline{y} &= \overline{\eta} + \overline{\varepsilon_y},
  \end{aligned}
\end{equation*}
где \( \overline{\xi}, \overline{\eta} \)
"--- векторы фактических значений входа и выхода объекта, \par
\( \overline{\theta} \)
"--- вектор фактических значений параметров, \par
\( \psi \)
"--- векторная функция регрессии, \par
\( \overline{x}, \overline{y} \)
"--- векторы наблюдаемых значений входной и выходной переменной, \par
\( \overline{\varepsilon_x}, \overline{\varepsilon_y} \)
"--- векторы независимых ошибок наблюдений входа и выхода.

Предложена следующая классификация стохастических систем.
\begin{enumerate}
\item Полустохастический объект --- объект с детерминированным входом и
  случайным выходом.
\item Стохастический объект первого типа --- объект со случайным входом и выходом.
  Возможно наличие ошибок в измерениях входных и выходных переменных.
\item Стохастический объектом второго типа --- детерминированный объект с ошибками
  в измерениях входных и выходных переменных.
\end{enumerate}

Рассмотрены классический и симметричный критерии идентификации стохастических систем,
минимизирующие суммы квадратов вертикальных и перпендикулярных расстояний от наблюдений
входных и выходных переменных до аппроксимирующей прямой или плоскости.

Выявлено, что области предпочтительного использования классического и симметричного
критериев для идентификации линейных стохастических систем второго типа
определены недостаточно четко, а также обоснована целесообразность
описания условий предпочтительного использования методов идентификации
нелинейных стохастических систем.
Исходя из этого определены задачи исследования.

\textbf{Вторая глава} посвящена определению условий предпочтительного использования
классического и симметричного критериев идентификации
для оценивания параметров стохастических объектов второго типа,
а также прогнозирования наблюдений их выхода по наблюдениям входа.
Разработаны алгоритмы классического метода наименьших квадратов и метода симметричной
аппроксимации, основанные на данных критериях.
Для сравнения точности методов использована модель линейной скалярной системы:
\begin{equation*}
  \begin{aligned}
  h &= \alpha + \beta \xi, \\
  x &= \xi + \varepsilon_x, \\
  y &= h + \varepsilon_y,
  \end{aligned}
\end{equation*}
где \( \xi, h \) "--- фактические значения входной и выходной переменной, \\
\hspace*{6mm} \( \alpha, \beta \) "--- фактические значения параметров объекта, \\
\hspace*{6mm} \( x, y \) "--- наблюдаемые значения входной и выходной переменной, \\
\hspace*{6mm} \( \varepsilon_x, \varepsilon_y \) "--- независимые ошибки наблюдений
входной и выходной переменной, распределенные по нормальному закону:
\(
\varepsilon_x = N(0, \sigma_{\varepsilon_x}),
\varepsilon_y = N(0, \sigma_{\varepsilon_y})
\).

Фактические значения входа системы \( \xi_i \) выбирались из равномерного в \( [0, 10] \) распределения.
Для получения каждой оценки \( \hat{\alpha}, \hat{\beta} \) использовались результаты
ста наблюдений \( ( x_i, y_i ), i = \overline{1, n}, n = 100 \).
Сравнение точности оценивания параметров модели производилось на основании
разности средних Евклидовых расстояний между точными значениями параметров
\( \alpha, \beta \) и их оценками, полученными методом наименьших квадратов
(\( \hat{\alpha}_{\text{МНК}}, \hat{\beta}_{\text{МНК}} \))
и методом симметриченой аппроксимации
(\( \hat{\alpha}_{\text{МСА}}, \hat{\beta}_{\text{МСА}} \)):
\begin{equation*}
  d =
  \frac{1}{k} \sum_{j=1}^k
  \Bigg(
  \sqrt{(\hat{\alpha}_{\text{МНК}_j} - \alpha)^2 + (\hat{\beta}_{\text{МНК}_j} - \beta)^2} -
  \sqrt{(\hat{\alpha}_{\text{МСА}_j} - \alpha)^2 + (\hat{\beta}_{\text{МСА}_j} - \beta)^2}
  \Bigg),
\end{equation*}
где \( k \) "--- число оценок.
Расчеты величины \( d \) производились в узлах сетки значений
\( \sigma_{\varepsilon_x}, \sigma_{\varepsilon_y} \) в прямоугольнике
\( [0, 2] \times [0, 2] \) с шагом 0{,}1.
В каждом узле сетки вычислялось сто оценок (\( k = 100 \)).

Моделирование показало, что метод симметричной аппроксимации оценивает
параметры линейных систем с большим коэффициентом усиления \( \beta \) более точно,
чем классический метод наименьших квадратов.
Для принятия решения о том, какой метод использовать более предпочтительно,
предложено использовать следующую эмпирическую зависимость:
<<Если условие
\begin{equation*}
  \sigma_{\varepsilon_y} > (0{,}7 + |\beta|) \sigma_{\varepsilon_x}
\end{equation*}
выполняется, то метод наименьших квадратов оценивает параметры линейной
стохастической системы второго типа более точно, чем метод симметричной аппроксимации.
В противном случае метод симметричной аппроксимации позволяет получить
оценки более высокой точности, чем метод наименьших квадратов>>.

Для сравнения точности прогнозирвания наблюдений выхода по наблюдениям входа
использовалась разность средних Евклидовых расстояний между наблюдениями
выхода модели и их оценками:
\begin{equation*}
  d =
  \frac{1}{k} \sum_{j=1}^k
  \Bigg(
  \sqrt{ \sum_{i=1}^n (\hat{\alpha}_{\text{МНК}_j} + \hat{\beta}_{\text{МНК}_j} x_{ij} - y_{ij})^2} -
  \sqrt{ \sum_{i=1}^n (\hat{\alpha}_{\text{МСА}_j} + \hat{\beta}_{\text{МСА}_j} x_{ij} - y_{ij})^2}
  \Bigg),
\end{equation*}
где \( k \) --- число оценок.

На основании результатов исследования зависимости данной величины от значений коэффициента усиления модели
и с.~к.~о. ошибок наблюдений рекомендовано
использовать метод наименьших квадратов для прогнозирования наблюдений выхода систем по наблюдениям входа.

Предметом \textbf{третьей главы} является проблема идентификации нелинейных стохастических систем.
Для решения задачи идентификации нелинейных стохастических систем второго типа
предложено использовать нелинейный метод наименьших квадратов и метод рядов Тейлора.
Приведены алгоритмы и примеры использования программных реализаций данных методов.
Для сравнения точности методов использована модель скалярной системы:
\begin{equation*}
  \begin{aligned}
    h &= \psi(\overline{\theta}, \xi), \\
    x &= \xi + \varepsilon_x, \\
    y &= h + \varepsilon_y,
  \end{aligned}
\end{equation*}
где \( \xi, h \) "--- фактические значения входной и выходной переменной, \\
\hspace*{7mm} \( \psi \) "--- скалярно-векторная функция регрессии, \\
\hspace*{7mm} \( \overline{\theta} = (\theta_1, \theta_2, \dotsc, \theta_m) \)
"--- вектор фактических значений параметров объекта, \\
\hspace*{7mm} \( x, y \) "--- наблюдаемые значения входной и выходной переменной, \\
\hspace*{6mm} \( \varepsilon_x, \varepsilon_y \)
"--- независимые ошибки измерений значений входной и выходной переменной,
распределенные по нормальному закону:
\(
\varepsilon_x = N(0, \sigma_{\varepsilon_x}),
\varepsilon_y = N(0, \sigma_{\varepsilon_y})
\).
Данная модель была использована для генерации наблюдений входа и выхода системы,
на основании которых были получены оценки её параметров
методом наименьших квадратов и методом рядов Тейлора.
Значения \( \xi_i \) выбирались из равномерного в \( [0, 10] \) распределения.
Для получения каждой оценки \( \hat{\overline{\theta}} \) использовались результаты
ста наблюдений \( ( x_i, y_i ), i = \overline{1, n}, n = 100 \).

На примере систем с линейными, параболическими, синусоидальными, экспоненциальными и
обратными функциями регрессии описана зависимость разности
средних Евклидовых расстояний между точными значениями параметров модели и их оценками
от с.~к.~о. ошибок наблюдений:
\begin{equation*}
  \begin{split}
    d(\sigma_{\varepsilon_x}, \sigma_{\varepsilon_y}) &=
    \dfrac{1}{k} \sum_{j=1}^k
    \sqrt{\sum_{\text{i=1}}^m (\hat{\theta}_{\text{МНК}_{ij}}(\sigma_{\varepsilon_x}, \sigma_{\varepsilon_y}) - \theta_{ij})^2} - \\
    &- \dfrac{1}{k} \sum_{j=1}^k
    \sqrt{\sum_{\text{i=1}}^m (\hat{\theta}_{\text{МРТ}_{ij}}(\sigma_{\varepsilon_x}, \sigma_{\varepsilon_y}) - \theta_{ij})^2},
  \end{split}
\end{equation*}
где \( k \) --- число оценок.
Расчеты величины \( d \) производились в узлах сетки значений
\( \sigma_{\varepsilon_x}, \sigma_{\varepsilon_y} \) в прямоугольнике
\( [0, 2] \times [0, 2] \) с шагом 0{,}1.
В каждом узле сетки вычислялось сто оценок (\( k = 100 \)).

Показано, что точность нелинейного метода наименьших квадратов существенным образом
зависит от того, насколько <<удачной>> является используемая им опорная точка.
В аналогичных условиях метод рядов Тейлора позволяет получать оценки параметров
приемлемой точности без необходимости указания опорной точки.

В заключении перечислены новые научные результаты, полученные в работе.
